{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "# < Data Loading >\n",
    "\n",
    "#Pandas 이용하여 DATA 불러오기 / DATA 살펴보기\n",
    "\n",
    "data = pd.read_csv('AMZN.csv').set_index('Date').astype(np.float)\n",
    "data.index = pd.to_datetime(data.index,format = '%Y-%m-%d')\n",
    "print(data.info())   \n",
    "\n",
    "# DataFrame을 tensorflow 연산을 위해 Array로 변경 \n",
    "\n",
    "data = data.values[0:]\n",
    "print(\"data shape: \", data.shape)\n",
    "\n",
    "# < DATA 전처리 >\n",
    "## 정규화 방식 ##\n",
    "\n",
    "# 1. Standardization\n",
    "def data_standardization(x):\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np - x_np.mean()) / x_np.std()\n",
    "\n",
    "# 2. Min-Max scaling\n",
    "def min_max_scaling(x):\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np - x_np.min()) / (x_np.max() - x_np.min() + 1e-7) # 1e-7은 0으로 나누는 오류 예방차원\n",
    "\n",
    "# 3. Reverse_min_max_scaling\n",
    "def reverse_min_max_scaling(org_x, x):\n",
    "    org_x_np = np.asarray(org_x)\n",
    "    x_np = np.asarray(x)\n",
    "    return (x_np * (org_x_np.max() - org_x_np.min() + 1e-7)) + org_x_np.min()\n",
    "\n",
    "\n",
    "## Input으로 사용되는 가격과 거래량 데이터의 스케일 차이가 크기때문에 각각 정규화 ##\n",
    "\n",
    "\n",
    "# 가격데이터 정규화\n",
    "# ['Open','High','Low','Volume','Close']에서 'Low' 까지\n",
    "price = data[:,:-2]\n",
    "norm_price = min_max_scaling(price) \n",
    "print(\"price.shape: \", price.shape)\n",
    "print(\"price[0]: \", price[0])\n",
    "print(\"norm_price[0]: \", norm_price[0])\n",
    "print(\"-\"*100)\n",
    "\n",
    "# 거래량형태 데이터를 정규화한다\n",
    "# ['Open','High','Low','Volume','Close']에서 'Volume'\n",
    "volume = data[:,-2:-1]\n",
    "norm_volume =data_standardization(volume) \n",
    "print(\"volume.shape: \", volume.shape)\n",
    "print(\"volume[0]: \", volume[0])\n",
    "print(\"norm_volume[0]: \", norm_volume[0])\n",
    "print(\"-\"*100)\n",
    "\n",
    "# price, volume data 재결합\n",
    "x = np.concatenate([norm_price, norm_volume], axis=1) \n",
    "print(\"x.shape: \", x.shape)\n",
    "print(\"x[0]: \", x[0])    # x의 첫 값\n",
    "print(\"x[-1]: \", x[-1])  # x의 마지막 값\n",
    "print(\"-\"*100)\n",
    "\n",
    "# y(정답set)는 'Close'\n",
    "close = data[:,-1:]\n",
    "y = min_max_scaling(close)\n",
    "print(\"y[0]: \",y[0])     # y의 첫 값\n",
    "print(\"y[-1]: \",y[-1])   # y의 마지막 값\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "\n",
    "input_data_column_num = 4  # 입력데이터의 컬럼 개수(Variable 개수) = Input dimension\n",
    "output_data_column_num = 1 # 결과데이터의 컬럼 개수 \n",
    "\n",
    "seq_length = 28          # 1개 시퀀스의 길이(시계열데이터 입력 개수)\n",
    "rnn_cell_hidden_dim = 20   # 각 셀의 (hidden)출력 크기\n",
    "forget_bias = 1.0          # 망각편향(기본값 1.0)\n",
    "num_stacked_layers = 1    # stacked LSTM layers 개수\n",
    "keep_prob = 1             # dropout할 때 keep할 비율\n",
    "\n",
    "epoch_num = 1000           # 에폭 횟수(학습용전체데이터를 몇 회 반복해서 학습할 것인가 입력)\n",
    "learning_rate = 0.01       # 학습률\n",
    "\n",
    "# 입출력용 DATA setting \n",
    "\n",
    "dataX = [] # 입력으로 사용될 Sequence Data\n",
    "dataY = [] # 출력(타켓)으로 사용\n",
    "\n",
    "for i in range(0, len(y) - seq_length):\n",
    "    _x = x[i : i+seq_length]\n",
    "    _y = y[i + seq_length] # 다음 나타날 주가(정답)\n",
    "    \n",
    "    dataX.append(_x) # dataX 리스트에 추가\n",
    "    dataY.append(_y) # dataY 리스트에 추가\n",
    "\n",
    "# 학습용/테스트용 데이터 생성\n",
    "\n",
    "# 전체 train:test 70% : 30%\n",
    "train_size = int(len(dataY) * 0.7)\n",
    "test_size = len(dataY) - train_size\n",
    "\n",
    "# 학습용 데이터 생성\n",
    "trainX = np.array(dataX[0:train_size])\n",
    "trainY = np.array(dataY[0:train_size])\n",
    "\n",
    "# 테스트용 데이터 생성\n",
    "testX = np.array(dataX[train_size:len(dataX)])\n",
    "testY = np.array(dataY[train_size:len(dataY)])\n",
    "\n",
    "# 텐서플로우 플레이스홀더 생성\n",
    "X = tf.placeholder(tf.float32, [None, seq_length, input_data_column_num])\n",
    "print(\"X: \", X)\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "print(\"Y: \", Y)\n",
    "\n",
    "# 검증용 측정지표를 산출하기 위한 targets, predictions를 생성한다\n",
    "targets = tf.placeholder(tf.float32, [None, 1])\n",
    "print(\"targets: \", targets)\n",
    "\n",
    "predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "print(\"predictions: \", predictions)\n",
    "\n",
    "# 모델(LSTM RNN) 생성 + FC layers\n",
    "\n",
    "def LSTM_cell():\n",
    "    \n",
    "    # forget_bias: biases of the forget gate (default: 1) in order to reduce the scale of forgetting in the beginning of the training.\n",
    "    \n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_cell_hidden_dim, \n",
    "                                         state_is_tuple=True, activation=None)\n",
    "#     if keep_prob < 1.0:\n",
    "#         cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "    return cell\n",
    "\n",
    "# num_stacked_layers개의 층으로 쌓인 Stacked RNNs 생성\n",
    "stackedRNNs = [LSTM_cell() for _ in range(num_stacked_layers)]\n",
    "multi_cells = tf.contrib.rnn.MultiRNNCell(stackedRNNs, state_is_tuple=True) \n",
    "\n",
    "# RNN Cell(여기서는 LSTM셀임)들을 연결\n",
    "outputs, _states = tf.nn.dynamic_rnn(multi_cells, X, dtype=tf.float32)\n",
    "print(\"outputs: \", outputs)\n",
    "\n",
    "# [:, -1]를 잘 살펴보자. LSTM RNN의 마지막 (hidden)출력만을 사용했다.\n",
    "# 과거 여러 거래일의 주가를 이용해서 다음날의 주가 1개를 예측하기때문에 MANY-TO-ONE형태이다\n",
    "Y_pred = tf.contrib.layers.fully_connected(outputs[:, -1], output_data_column_num, activation_fn=None)\n",
    "\n",
    "# Loss function define\n",
    "loss = tf.reduce_sum(tf.square(Y_pred - Y))\n",
    "\n",
    "# Optimizer\n",
    "train = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# RMSE(Root Mean Square Error)\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.squared_difference(targets, predictions)))\n",
    "\n",
    "# Learning \n",
    "\n",
    "train_error_summary = [] # 학습용 데이터의 오류를 중간 중간 기록한다\n",
    "test_error_summary = []  # 테스트용 데이터의 오류를 중간 중간 기록한다\n",
    "test_predict = ''        # 테스트용데이터로 예측한 결과\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('Learning Start!')\n",
    "    \n",
    "    for epoch in range(epoch_num):\n",
    "        _, _loss = sess.run([train, loss], feed_dict={X: trainX, Y: trainY})\n",
    "        \n",
    "        if ((epoch+1) % 200 == 0) or (epoch == epoch_num-1): # 100번째마다 또는 마지막 epoch인 경우\n",
    "            \n",
    "            # 학습용데이터로 rmse오차를 구한다\n",
    "            train_predict = sess.run(Y_pred, feed_dict={X: trainX})\n",
    "            train_error = sess.run(rmse, feed_dict={targets: trainY, predictions: train_predict})\n",
    "            train_error_summary.append(train_error)\n",
    "\n",
    "            # 테스트용데이터로 rmse오차를 구한다\n",
    "            test_predict = sess.run(Y_pred, feed_dict={X: testX})\n",
    "            test_error = sess.run(rmse, feed_dict={targets: testY, predictions: test_predict})\n",
    "            test_error_summary.append(test_error)\n",
    "\n",
    "            # 현재 오류를 출력한다\n",
    "            print(\"epoch: {}, train_error(A): {}, test_error(B): {}, B-A: {}\".format(epoch+1, train_error, test_error, test_error-train_error))\n",
    "    \n",
    "    recent_data = np.array([x[len(x)-seq_length : ]])  \n",
    "    \n",
    "    # 내일 종가를 예측해본다\n",
    "    ostest_predict = sess.run(Y_pred, feed_dict={X: recent_data})\n",
    "\n",
    "    print(\"ostest_predict\", ostest_predict[0])\n",
    "    ostest_predict = reverse_min_max_scaling(close,ostest_predict) # 금액데이터 역정규화한다\n",
    "    print(\"Predicted stock price\", ostest_predict[0]) # 예측한 주가를 출력한다\n",
    "    print(\"Real price : \" , close[len(close)-seq_length : ][0])\n",
    "    \n",
    "# 결과 그래프 출력\n",
    "plt.figure(1)\n",
    "plt.plot(train_error_summary, 'gold',label='train error')\n",
    "plt.plot(test_error_summary, 'b',label='test error')\n",
    "plt.title('Cost')\n",
    "plt.xlabel('Epoch(x100)')\n",
    "plt.ylabel('Root Mean Square Error')\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(testY, 'r',label='Real price in test set')\n",
    "plt.plot(test_predict, 'b',label='Prediction price')\n",
    "plt.title('Real vs Test set predict')\n",
    "plt.xlabel('Time Period')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend(loc='best')\n",
    "plt.show()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
